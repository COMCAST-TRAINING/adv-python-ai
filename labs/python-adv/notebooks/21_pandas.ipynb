{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "579bd630",
   "metadata": {},
   "source": [
    "# 21 Pandas\n",
    "\n",
    "**Pandas** is a powerful Python library for data manipulation and analysis. It provides easy-to-use data structures and data analysis tools.\n",
    "\n",
    "**Key Use Cases:**\n",
    "- **Data Cleaning**: Handle missing values, duplicates, and inconsistent data\n",
    "- **Data Transformation**: Filter, sort, merge, and reshape datasets\n",
    "- **Data Analysis**: Statistical analysis, aggregation, and grouping operations\n",
    "- **Time Series**: Work with date/time data and perform time-based operations\n",
    "- **File I/O**: Read/write data from CSV, Excel, SQL databases, and more\n",
    "- **Data Visualization**: Basic plotting capabilities integrated with matplotlib\n",
    "\n",
    "**Why Pandas?** Built on NumPy, Pandas introduces Series (1D) and DataFrame (2D) for labeled data. It handles heterogeneous data, missing values, and complex operations efficiently. Essential for data science workflows, bridging raw data to insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdbf8ad",
   "metadata": {},
   "source": [
    "## Import Pandas\n",
    "\n",
    "Import Pandas and NumPy for data manipulation. Checking versions ensures compatibility.\n",
    "\n",
    "**Details:** `import pandas as pd` is standard. NumPy is often imported alongside for array operations. Version checks help debug issues from library updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3522b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Pandas version:\", pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fbd2de",
   "metadata": {},
   "source": [
    "## Creating Series and DataFrames\n",
    "\n",
    "Series are 1D labeled arrays; DataFrames are 2D tables with rows/columns.\n",
    "\n",
    "**Details:** Series have an index; DataFrames have row/column indices. Created from lists, dicts, or NumPy arrays. Dict keys become columns. Crucial for structured data handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd17b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series\n",
    "s = pd.Series([1, 3, 5, 6, 8])\n",
    "print(\"Series:\", s)\n",
    "\n",
    "# DataFrame from dict\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'], 'Age': [25, 30, 35], 'City': ['NYC', 'LA', 'Chicago']}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4da968e",
   "metadata": {},
   "source": [
    "## Reading and Writing Data\n",
    "\n",
    "Pandas supports various formats like CSV, Excel, JSON. `to_csv()` writes; `read_csv()` reads.\n",
    "\n",
    "**Details:** `index=False` avoids saving row indices. Handles large files with chunking. Essential for ETL processes in data pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13948351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data\n",
    "df.to_csv('sample.csv', index=False)\n",
    "df_read = pd.read_csv('sample.csv')\n",
    "print(\"Read CSV:\")\n",
    "print(df_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6821b3a",
   "metadata": {},
   "source": [
    "## Data Inspection\n",
    "\n",
    "`head()`, `info()`, `describe()` provide overviews. `shape`, `columns`, `index` give structure info.\n",
    "\n",
    "**Details:** `head(n)` shows first n rows. `info()` reveals dtypes and nulls. `describe()` gives stats for numeric columns. First steps in EDA (Exploratory Data Analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118ac9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Head:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"Describe:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"Index:\", df.index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749ff47b",
   "metadata": {},
   "source": [
    "## Indexing and Selection\n",
    "\n",
    "Select columns, rows, or subsets using labels or positions.\n",
    "\n",
    "**Details:** `df['col']` for columns; `loc[]` for label-based; `iloc[]` for position-based. Boolean indexing filters data. Powerful for querying datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0a79c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Column selection:\")\n",
    "print(df['Name'])\n",
    "\n",
    "print(\"Multiple columns:\")\n",
    "print(df[['Name', 'Age']])\n",
    "\n",
    "print(\"Row selection by label:\")\n",
    "print(df.loc[0])\n",
    "\n",
    "print(\"Row selection by position:\")\n",
    "print(df.iloc[0])\n",
    "\n",
    "print(\"Boolean indexing:\")\n",
    "print(df[df['Age'] > 25])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebf46c7",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Handle missing data with `dropna()` or `fillna()`. Pandas excels at this.\n",
    "\n",
    "**Details:** `dropna()` removes rows/columns with NaNs. `fillna()` imputes values (mean, median, etc.). Critical for real-world data, which often has gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9763d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some missing data\n",
    "df_dirty = df.copy()\n",
    "df_dirty.loc[0, 'Age'] = np.nan\n",
    "print(\"Data with NaN:\")\n",
    "print(df_dirty)\n",
    "\n",
    "print(\"Drop NaN:\")\n",
    "print(df_dirty.dropna())\n",
    "\n",
    "print(\"Fill NaN:\")\n",
    "print(df_dirty.fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487e3ecb",
   "metadata": {},
   "source": [
    "## Data Operations\n",
    "\n",
    "Add columns, compute aggregations, or transform data.\n",
    "\n",
    "**Details:** Vectorized operations are fast. `apply()` for custom functions. Enables feature engineering in ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6400765",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age_Double'] = df['Age'] * 2\n",
    "print(\"Added column:\")\n",
    "print(df)\n",
    "\n",
    "print(\"Mean age:\", df['Age'].mean())\n",
    "\n",
    "print(\"Value counts:\")\n",
    "print(df['City'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9656eb9f",
   "metadata": {},
   "source": [
    "## Grouping and Aggregation\n",
    "\n",
    "`groupby()` splits data by keys, applies functions, combines results.\n",
    "\n",
    "**Details:** Like SQL GROUP BY. Supports multiple aggregations. Essential for summarizing data (e.g., sales by region)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a51a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add more data for grouping\n",
    "df_extended = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'Age': [25, 30, 35, 28, 32],\n",
    "    'City': ['NYC', 'LA', 'Chicago', 'NYC', 'LA'],\n",
    "    'Salary': [50000, 60000, 70000, 55000, 65000]\n",
    "})\n",
    "\n",
    "print(\"Group by City and mean:\")\n",
    "print(df_extended.groupby('City').mean(numeric_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436673a5",
   "metadata": {},
   "source": [
    "## Merging and Joining\n",
    "\n",
    "Combine DataFrames with `merge()` (like SQL joins) or `concat()` (stacking).\n",
    "\n",
    "**Details:** `merge()` on keys; `concat()` along axes. Handles relational data. Key for integrating multiple sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194aabce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'key': ['A', 'B', 'C'], 'value1': [1, 2, 3]})\n",
    "df2 = pd.DataFrame({'key': ['A', 'B', 'D'], 'value2': [4, 5, 6]})\n",
    "\n",
    "print(\"Merge:\")\n",
    "print(pd.merge(df1, df2, on='key'))\n",
    "\n",
    "print(\"Concat:\")\n",
    "print(pd.concat([df1, df2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e3e7f2",
   "metadata": {},
   "source": [
    "## Time Series\n",
    "\n",
    "Pandas has strong datetime support with `DatetimeIndex` and resampling.\n",
    "\n",
    "**Details:** `date_range()` creates dates. `resample()` aggregates by time (e.g., daily to monthly). Vital for financial, IoT, or temporal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c771c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range('2023-01-01', periods=5, freq='D')\n",
    "ts = pd.Series(np.random.randn(5), index=dates)\n",
    "print(\"Time Series:\")\n",
    "print(ts)\n",
    "\n",
    "print(\"Resample monthly:\")\n",
    "print(ts.resample('M').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2372e7de",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Basic plotting with `plot()`. Integrates with Matplotlib/Seaborn.\n",
    "\n",
    "**Details:** Quick charts for exploration. `kind='bar'` for categories. Not for publication-quality plots, but handy for insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b34d174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic plot (would show in notebook)\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    df_extended.plot(x='Name', y='Salary', kind='pie')\n",
    "    print(\"Plot created\")\n",
    "except Exception as e:\n",
    "    print(f\"Plotting not available: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169db263",
   "metadata": {},
   "source": [
    "## Performance Tips\n",
    "\n",
    "Use vectorized operations over loops for speed.\n",
    "\n",
    "**Details:** Pandas is optimized for vectorization. For big data, consider Dask or chunking. Profiling with `%%timeit` helps identify bottlenecks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea315d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorized operations are preferred\n",
    "df_large = pd.DataFrame({'A': np.random.randn(1000), 'B': np.random.randn(1000)})\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "result = df_large['A'] + df_large['B']\n",
    "end = time.time()\n",
    "print(\"Vectorized operation time:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59982624",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Remove temporary files to maintain a clean environment.\n",
    "\n",
    "**Details:** Prevents disk clutter. `os.remove()` deletes files. Good habit in scripts or notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c897c821",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for f in ['sample.csv']:\n",
    "    if os.path.exists(f):\n",
    "        os.remove(f)\n",
    "        print(f\"Removed: {f}\")\n",
    "\n",
    "print(\"\\nCleanup complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
