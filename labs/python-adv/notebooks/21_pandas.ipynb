{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "579bd630",
   "metadata": {},
   "source": [
    "# 21 Pandas\n",
    "\n",
    "**Pandas** is a powerful Python library for data manipulation and analysis. It provides easy-to-use data structures and data analysis tools.\n",
    "\n",
    "**Key Use Cases:**\n",
    "- **Data Cleaning**: Handle missing values, duplicates, and inconsistent data\n",
    "- **Data Transformation**: Filter, sort, merge, and reshape datasets\n",
    "- **Data Analysis**: Statistical analysis, aggregation, and grouping operations\n",
    "- **Time Series**: Work with date/time data and perform time-based operations\n",
    "- **File I/O**: Read/write data from CSV, Excel, SQL databases, and more\n",
    "- **Data Visualization**: Basic plotting capabilities integrated with matplotlib\n",
    "\n",
    "**Why Pandas?** Built on NumPy, Pandas introduces Series (1D) and DataFrame (2D) for labeled data. It handles heterogeneous data, missing values, and complex operations efficiently. Essential for data science workflows, bridging raw data to insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdbf8ad",
   "metadata": {},
   "source": [
    "## Import Pandas\n",
    "\n",
    "Import Pandas and NumPy for data manipulation. Checking versions ensures compatibility.\n",
    "\n",
    "**Details:** `import pandas as pd` is standard. NumPy is often imported alongside for array operations. Version checks help debug issues from library updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3522b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Pandas version:\", pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fbd2de",
   "metadata": {},
   "source": [
    "## Creating Series and DataFrames\n",
    "\n",
    "Series are 1D labeled arrays; DataFrames are 2D tables with rows/columns.\n",
    "\n",
    "**Details:** Series have an index; DataFrames have row/column indices. Created from lists, dicts, or NumPy arrays. Dict keys become columns. Crucial for structured data handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cd17b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series: 0    1\n",
      "1    3\n",
      "2    5\n",
      "3    6\n",
      "4    8\n",
      "dtype: int64\n",
      "DataFrame:\n",
      "      Name  Age     City\n",
      "0    Alice   25      NYC\n",
      "1      Bob   30       LA\n",
      "2  Charlie   35  Chicago\n"
     ]
    }
   ],
   "source": [
    "# Series\n",
    "s = pd.Series([1, 3, 5, 6, 8])\n",
    "print(\"Series:\", s)\n",
    "\n",
    "# DataFrame from dict\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'], 'Age': [25, 30, 35], 'City': ['NYC', 'LA', 'Chicago']}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4da968e",
   "metadata": {},
   "source": [
    "## Reading and Writing Data\n",
    "\n",
    "Pandas supports various formats like CSV, Excel, JSON. `to_csv()` writes; `read_csv()` reads.\n",
    "\n",
    "**Details:** `index=False` avoids saving row indices. Handles large files with chunking. Essential for ETL processes in data pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13948351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read CSV:\n",
      "      Name  Age     City\n",
      "0    Alice   25      NYC\n",
      "1      Bob   30       LA\n",
      "2  Charlie   35  Chicago\n"
     ]
    }
   ],
   "source": [
    "# Create sample data\n",
    "df.to_csv('sample.csv', index=False)\n",
    "df_read = pd.read_csv('sample.csv')\n",
    "print(\"Read CSV:\")\n",
    "print(df_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6821b3a",
   "metadata": {},
   "source": [
    "## Data Inspection\n",
    "\n",
    "`head()`, `info()`, `describe()` provide overviews. `shape`, `columns`, `index` give structure info.\n",
    "\n",
    "**Details:** `head(n)` shows first n rows. `info()` reveals dtypes and nulls. `describe()` gives stats for numeric columns. First steps in EDA (Exploratory Data Analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "118ac9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head:\n",
      "      Name  Age     City\n",
      "0    Alice   25      NYC\n",
      "1      Bob   30       LA\n",
      "2  Charlie   35  Chicago\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Name    3 non-null      object\n",
      " 1   Age     3 non-null      int64 \n",
      " 2   City    3 non-null      object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 204.0+ bytes\n",
      "None\n",
      "Describe:\n",
      "        Age\n",
      "count   3.0\n",
      "mean   30.0\n",
      "std     5.0\n",
      "min    25.0\n",
      "25%    27.5\n",
      "50%    30.0\n",
      "75%    32.5\n",
      "max    35.0\n",
      "Shape: (3, 3)\n",
      "Columns: ['Name', 'Age', 'City']\n",
      "Index: [0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Head:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"Describe:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"Index:\", df.index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749ff47b",
   "metadata": {},
   "source": [
    "## Indexing and Selection\n",
    "\n",
    "Select columns, rows, or subsets using labels or positions.\n",
    "\n",
    "**Details:** `df['col']` for columns; `loc[]` for label-based; `iloc[]` for position-based. Boolean indexing filters data. Powerful for querying datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0a79c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Column selection:\")\n",
    "print(df['Name'])\n",
    "\n",
    "print(\"Multiple columns:\")\n",
    "print(df[['Name', 'Age']])\n",
    "\n",
    "print(\"Row selection by label:\")\n",
    "print(df.loc[0])\n",
    "\n",
    "print(\"Row selection by position:\")\n",
    "print(df.iloc[0])\n",
    "\n",
    "print(\"Boolean indexing:\")\n",
    "print(df[df['Age'] > 25])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebf46c7",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Handle missing data with `dropna()` or `fillna()`. Pandas excels at this.\n",
    "\n",
    "**Details:** `dropna()` removes rows/columns with NaNs. `fillna()` imputes values (mean, median, etc.). Critical for real-world data, which often has gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9763d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some missing data\n",
    "df_dirty = df.copy()\n",
    "df_dirty.loc[0, 'Age'] = np.nan\n",
    "print(\"Data with NaN:\")\n",
    "print(df_dirty)\n",
    "\n",
    "print(\"Drop NaN:\")\n",
    "print(df_dirty.dropna())\n",
    "\n",
    "print(\"Fill NaN:\")\n",
    "print(df_dirty.fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487e3ecb",
   "metadata": {},
   "source": [
    "## Data Operations\n",
    "\n",
    "Add columns, compute aggregations, or transform data.\n",
    "\n",
    "**Details:** Vectorized operations are fast. `apply()` for custom functions. Enables feature engineering in ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6400765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added column:\n",
      "      Name  Age     City  Age_Double\n",
      "0    Alice   25      NYC          50\n",
      "1      Bob   30       LA          60\n",
      "2  Charlie   35  Chicago          70\n",
      "Mean age: 30.0\n",
      "Value counts:\n",
      "City\n",
      "NYC        1\n",
      "LA         1\n",
      "Chicago    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['Age_Double'] = df['Age'] * 2\n",
    "print(\"Added column:\")\n",
    "print(df)\n",
    "\n",
    "print(\"Mean age:\", df['Age'].mean())\n",
    "\n",
    "print(\"Value counts:\")\n",
    "print(df['City'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9656eb9f",
   "metadata": {},
   "source": [
    "## Grouping and Aggregation\n",
    "\n",
    "`groupby()` splits data by keys, applies functions, combines results.\n",
    "\n",
    "**Details:** Like SQL GROUP BY. Supports multiple aggregations. Essential for summarizing data (e.g., sales by region)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a51a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add more data for grouping\n",
    "df_extended = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'Age': [25, 30, 35, 28, 32],\n",
    "    'City': ['NYC', 'LA', 'Chicago', 'NYC', 'LA'],\n",
    "    'Salary': [50000, 60000, 70000, 55000, 65000]\n",
    "})\n",
    "\n",
    "print(\"Group by City and mean:\")\n",
    "print(df_extended.groupby('City').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436673a5",
   "metadata": {},
   "source": [
    "## Merging and Joining\n",
    "\n",
    "Combine DataFrames with `merge()` (like SQL joins) or `concat()` (stacking).\n",
    "\n",
    "**Details:** `merge()` on keys; `concat()` along axes. Handles relational data. Key for integrating multiple sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "194aabce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge:\n",
      "  key  value1  value2\n",
      "0   A       1       4\n",
      "1   B       2       5\n",
      "Concat:\n",
      "  key  value1  value2\n",
      "0   A     1.0     NaN\n",
      "1   B     2.0     NaN\n",
      "2   C     3.0     NaN\n",
      "0   A     NaN     4.0\n",
      "1   B     NaN     5.0\n",
      "2   D     NaN     6.0\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'key': ['A', 'B', 'C'], 'value1': [1, 2, 3]})\n",
    "df2 = pd.DataFrame({'key': ['A', 'B', 'D'], 'value2': [4, 5, 6]})\n",
    "\n",
    "print(\"Merge:\")\n",
    "print(pd.merge(df1, df2, on='key'))\n",
    "\n",
    "print(\"Concat:\")\n",
    "print(pd.concat([df1, df2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e3e7f2",
   "metadata": {},
   "source": [
    "## Time Series\n",
    "\n",
    "Pandas has strong datetime support with `DatetimeIndex` and resampling.\n",
    "\n",
    "**Details:** `date_range()` creates dates. `resample()` aggregates by time (e.g., daily to monthly). Vital for financial, IoT, or temporal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c771c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series:\n",
      "2023-01-01    0.224397\n",
      "2023-01-02   -0.101360\n",
      "2023-01-03   -0.834172\n",
      "2023-01-04   -0.671182\n",
      "2023-01-05    0.665915\n",
      "Freq: D, dtype: float64\n",
      "Resample monthly:\n",
      "2023-01-31   -0.14328\n",
      "Freq: ME, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7z/dbyd2p2x4hbc3qmgcdlk0b780000gp/T/ipykernel_14660/2993271475.py:7: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  print(ts.resample('M').mean())\n"
     ]
    }
   ],
   "source": [
    "dates = pd.date_range('2023-01-01', periods=5, freq='D')\n",
    "ts = pd.Series(np.random.randn(5), index=dates)\n",
    "print(\"Time Series:\")\n",
    "print(ts)\n",
    "\n",
    "print(\"Resample monthly:\")\n",
    "print(ts.resample('M').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2372e7de",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Basic plotting with `plot()`. Integrates with Matplotlib/Seaborn.\n",
    "\n",
    "**Details:** Quick charts for exploration. `kind='bar'` for categories. Not for publication-quality plots, but handy for insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b34d174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting not available in this environment\n"
     ]
    }
   ],
   "source": [
    "# Basic plot (would show in notebook)\n",
    "try:\n",
    "    df_extended.plot(x='Name', y='Salary', kind='bar')\n",
    "    print(\"Plot created\")\n",
    "except:\n",
    "    print(\"Plotting not available in this environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169db263",
   "metadata": {},
   "source": [
    "## Performance Tips\n",
    "\n",
    "Use vectorized operations over loops for speed.\n",
    "\n",
    "**Details:** Pandas is optimized for vectorization. For big data, consider Dask or chunking. Profiling with `%%timeit` helps identify bottlenecks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea315d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorized operations are preferred\n",
    "df_large = pd.DataFrame({'A': np.random.randn(1000), 'B': np.random.randn(1000)})\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "result = df_large['A'] + df_large['B']\n",
    "end = time.time()\n",
    "print(\"Vectorized operation time:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59982624",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Remove temporary files to maintain a clean environment.\n",
    "\n",
    "**Details:** Prevents disk clutter. `os.remove()` deletes files. Good habit in scripts or notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c897c821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed: sample.csv\n",
      "\n",
      "Cleanup complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for f in ['sample.csv']:\n",
    "    if os.path.exists(f):\n",
    "        os.remove(f)\n",
    "        print(f\"Removed: {f}\")\n",
    "\n",
    "print(\"\\nCleanup complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
