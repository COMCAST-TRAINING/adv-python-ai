{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4235023b",
   "metadata": {},
   "source": [
    "# Simple Regression Task\n",
    "\n",
    "This notebook demonstrates various regression techniques using scikit-learn:\n",
    "1. Simple Linear Regression\n",
    "2. Polynomial Regression\n",
    "3. Ridge and Lasso Regression\n",
    "4. Model Evaluation and Comparison\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand how linear regression works\n",
    "- Learn to evaluate regression models\n",
    "- Compare different regularization techniques\n",
    "- Visualize regression results\n",
    "\n",
    "---\n",
    "\n",
    "## Machine Learning Pipeline Overview\n",
    "\n",
    "A typical ML pipeline consists of the following stages:\n",
    "\n",
    "```\n",
    "┌─────────────┐    ┌──────────────┐    ┌─────────────┐    ┌────────────┐    ┌────────────┐\n",
    "│ Data        │ -> │ Data         │ -> │ Feature     │ -> │ Model      │ -> │ Model      │\n",
    "│ Collection  │    │ Preprocessing│    │ Engineering │    │ Training   │    │ Evaluation │\n",
    "└─────────────┘    └──────────────┘    └─────────────┘    └────────────┘    └────────────┘\n",
    "                          │                   │                 │                  │\n",
    "                          v                   v                 v                  v\n",
    "                   - Handle missing    - Create new      - Split data      - Calculate\n",
    "                     values              features        - Fit model         metrics\n",
    "                   - Scale/Normalize   - Transform       - Cross-validate  - Compare models\n",
    "                   - Encode categories   variables       - Tune params     - Select best\n",
    "```\n",
    "\n",
    "## Core Concepts in Regression\n",
    "\n",
    "### What is Regression?\n",
    "Regression is a supervised learning technique used to predict **continuous numerical values**. Unlike classification (which predicts categories), regression predicts quantities like price, temperature, or sales.\n",
    "\n",
    "### Key Terminology:\n",
    "| Term | Definition |\n",
    "|------|------------|\n",
    "| **Features (X)** | Input variables used for prediction (independent variables) |\n",
    "| **Target (y)** | The value we want to predict (dependent variable) |\n",
    "| **Training Set** | Data used to train the model (typically 70-80%) |\n",
    "| **Test Set** | Data used to evaluate model performance (typically 20-30%) |\n",
    "| **Coefficient** | Weight assigned to each feature showing its impact on prediction |\n",
    "| **Intercept** | The baseline prediction when all features are zero |\n",
    "| **Residual** | Difference between actual and predicted values |\n",
    "| **Overfitting** | Model memorizes training data but fails on new data |\n",
    "| **Underfitting** | Model is too simple to capture underlying patterns |\n",
    "\n",
    "### The Bias-Variance Tradeoff:\n",
    "- **High Bias** (Underfitting): Model is too simple, high error on both train and test\n",
    "- **High Variance** (Overfitting): Model is too complex, low train error but high test error\n",
    "- **Goal**: Find the sweet spot with good performance on both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0886f87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa745103",
   "metadata": {},
   "source": [
    "### ✅ Interpretation: Library Imports\n",
    "\n",
    "The libraries we imported serve specific purposes:\n",
    "- **NumPy**: Numerical computations and array operations\n",
    "- **Pandas**: Data manipulation and analysis\n",
    "- **Matplotlib/Seaborn**: Data visualization\n",
    "- **Scikit-learn**: Machine learning algorithms and utilities\n",
    "  - `train_test_split`: Splits data into training and testing sets\n",
    "  - `LinearRegression, Ridge, Lasso`: Different regression algorithms\n",
    "  - `PolynomialFeatures`: Creates polynomial features for non-linear relationships\n",
    "  - `StandardScaler`: Normalizes features to similar scales\n",
    "  - `Pipeline`: Chains preprocessing and modeling steps\n",
    "  - Various metrics: `mean_squared_error`, `r2_score`, etc.\n",
    "\n",
    "Setting `random_state=42` ensures reproducibility - you'll get the same results each time you run the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108c8eb3",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Data\n",
    "\n",
    "Let's create a simple dataset with a linear relationship plus some noise.\n",
    "\n",
    "### Why Synthetic Data?\n",
    "Using synthetic data allows us to:\n",
    "1. **Know the true relationship** - We define it, so we can verify our model finds it\n",
    "2. **Control complexity** - Add or remove noise to test model robustness\n",
    "3. **Learn without real-world messiness** - Focus on understanding algorithms\n",
    "\n",
    "### Our Data Scenario:\n",
    "We're simulating house prices based on size:\n",
    "- **True relationship**: `Price = 0.15 × Size + 50 + noise`\n",
    "- This means each additional square foot adds $150 to the price\n",
    "- Base price is $50,000\n",
    "- Noise represents factors we can't capture (location, condition, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a5e9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n_samples = 200\n",
    "\n",
    "# Feature: House size (in square feet)\n",
    "X = np.random.uniform(500, 3500, n_samples).reshape(-1, 1)\n",
    "print(X)\n",
    "\n",
    "# Target: House price (in thousands)\n",
    "# True relationship: price = 0.15 * size + 50 + noise\n",
    "y = 0.15 * X.flatten() + 50 + np.random.normal(0, 30, n_samples)\n",
    "\n",
    "# Create a DataFrame for easier visualization\n",
    "df = pd.DataFrame({\n",
    "    'Size (sq ft)': X.flatten(),\n",
    "    'Price ($K)': y\n",
    "})\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"\\nData Statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818dba3f",
   "metadata": {},
   "source": [
    "### ✅ Interpretation: Data Generation Results\n",
    "\n",
    "**What the output tells us:**\n",
    "- We have 200 samples with 1 feature (house size)\n",
    "- Size ranges from ~500 to ~3500 sq ft (see min/max)\n",
    "- Price ranges based on our formula plus random noise\n",
    "\n",
    "**Key Statistics to Note:**\n",
    "- **Mean size**: Should be around 2000 sq ft (middle of our range)\n",
    "- **Mean price**: Should be around `0.15 × 2000 + 50 = 350` ($350K)\n",
    "- **Std (standard deviation)**: Shows data spread - higher std means more variability\n",
    "\n",
    "**Why this matters:**\n",
    "Understanding your data distribution is crucial before modeling. Outliers, skewness, or unusual ranges can significantly affect model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f6b84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X, y, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "plt.xlabel('House Size (sq ft)', fontsize=12)\n",
    "plt.ylabel('Price ($K)', fontsize=12)\n",
    "plt.title('House Size vs Price', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaec7f3",
   "metadata": {},
   "source": [
    "### ✅ Interpretation: Scatter Plot\n",
    "\n",
    "**What to look for:**\n",
    "1. **Linear trend**: Points generally follow an upward diagonal pattern ✓\n",
    "2. **Spread around trend**: The vertical spread shows the noise we added\n",
    "3. **No obvious clusters or outliers**: Data is fairly uniform\n",
    "\n",
    "**Visual Confirmation:**\n",
    "- The positive correlation is clear - larger houses cost more\n",
    "- The relationship appears linear (no curves), confirming linear regression is appropriate\n",
    "- The noise creates vertical spread, which our model will try to minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e29e985",
   "metadata": {},
   "source": [
    "## 2. Simple Linear Regression\n",
    "\n",
    "Linear regression finds the best-fit line: **y = mx + b**\n",
    "\n",
    "Where:\n",
    "- m = slope (coefficient)\n",
    "- b = intercept\n",
    "\n",
    "### How Does It Work?\n",
    "\n",
    "Linear regression uses **Ordinary Least Squares (OLS)** to find the line that minimizes the sum of squared residuals:\n",
    "\n",
    "```\n",
    "Minimize: Σ(yᵢ - ŷᵢ)² = Σ(yᵢ - (mx + b))²\n",
    "```\n",
    "\n",
    "**Intuition**: Imagine dropping perpendicular lines from each point to the regression line. OLS finds the line where the sum of these squared distances is smallest.\n",
    "\n",
    "### Assumptions of Linear Regression:\n",
    "1. **Linearity**: Relationship between X and y is linear\n",
    "2. **Independence**: Observations are independent\n",
    "3. **Homoscedasticity**: Constant variance of residuals\n",
    "4. **Normality**: Residuals are normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4bcf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f2d6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Model parameters\n",
    "print(\"Model Parameters:\")\n",
    "print(f\"  Coefficient (slope): {model.coef_[0]:.4f}\")\n",
    "print(f\"  Intercept: {model.intercept_:.4f}\")\n",
    "print(f\"\\nEquation: Price = {model.coef_[0]:.4f} × Size + {model.intercept_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a218fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_regression(y_true, y_pred, dataset_name=\"\"):\n",
    "    \"\"\"Calculate and display regression metrics.\"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{dataset_name} Metrics:\")\n",
    "    print(f\"  Mean Squared Error (MSE):     {mse:.4f}\")\n",
    "    print(f\"  Root Mean Squared Error:      {rmse:.4f}\")\n",
    "    print(f\"  Mean Absolute Error (MAE):    {mae:.4f}\")\n",
    "    print(f\"  R² Score:                     {r2:.4f}\")\n",
    "    \n",
    "    return {'mse': mse, 'rmse': rmse, 'mae': mae, 'r2': r2}\n",
    "\n",
    "train_metrics = evaluate_regression(y_train, y_pred_train, \"Training Set\")\n",
    "test_metrics = evaluate_regression(y_test, y_pred_test, \"Test Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9d3ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the regression line\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot 1: Training data with regression line\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_train, y_train, alpha=0.6, label='Training Data')\n",
    "plt.plot(X_train, y_pred_train, color='red', linewidth=2, label='Regression Line')\n",
    "plt.xlabel('House Size (sq ft)')\n",
    "plt.ylabel('Price ($K)')\n",
    "plt.title('Training Data')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Test data with predictions\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_test, y_test, alpha=0.6, color='green', label='Test Data')\n",
    "plt.plot(X_test, y_pred_test, color='red', linewidth=2, label='Predictions')\n",
    "plt.xlabel('House Size (sq ft)')\n",
    "plt.ylabel('Price ($K)')\n",
    "plt.title(f'Test Data (R² = {test_metrics[\"r2\"]:.4f})')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f0b9ae",
   "metadata": {},
   "source": [
    "### ✅ Interpretation: Train-Test Split\n",
    "\n",
    "**Why Split the Data?**\n",
    "- **Training set (80%)**: Used to teach the model the patterns\n",
    "- **Test set (20%)**: Used to evaluate how well the model generalizes to new data\n",
    "\n",
    "**Critical Concept:**\n",
    "Never evaluate a model on the same data it was trained on! This would be like giving students the exact exam questions during study - they'd score well but not truly understand the material.\n",
    "\n",
    "**Our split:**\n",
    "- 160 samples for training\n",
    "- 40 samples for testing\n",
    "\n",
    "The `random_state=42` ensures the same split every time, making results reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d57dc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30fc230",
   "metadata": {},
   "source": [
    "### ✅ Interpretation: Model Parameters\n",
    "\n",
    "**Compare to True Values:**\n",
    "| Parameter | True Value | Model Found | Difference |\n",
    "|-----------|------------|-------------|------------|\n",
    "| Coefficient | 0.15 | ~0.15 | Very close! |\n",
    "| Intercept | 50 | ~50 | Very close! |\n",
    "\n",
    "**What This Means:**\n",
    "- **Coefficient ≈ 0.15**: For every 1 sq ft increase, price increases by ~$0.15K ($150)\n",
    "- **Intercept ≈ 50**: Base price when size is 0 (theoretical, not practical)\n",
    "\n",
    "**Success Indicator:**\n",
    "Our model successfully recovered the true underlying relationship despite the noise! This demonstrates that with enough data, linear regression can find the signal through the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1341c7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02001769",
   "metadata": {},
   "source": [
    "### ✅ Interpretation: Evaluation Metrics\n",
    "\n",
    "**Understanding Each Metric:**\n",
    "\n",
    "| Metric | Formula | Good Values | Interpretation |\n",
    "|--------|---------|-------------|----------------|\n",
    "| **MSE** | Σ(y - ŷ)²/n | Lower is better | Average squared error - penalizes large errors heavily |\n",
    "| **RMSE** | √MSE | Lower is better | In same units as target - more interpretable than MSE |\n",
    "| **MAE** | Σ\\|y - ŷ\\|/n | Lower is better | Average absolute error - less sensitive to outliers |\n",
    "| **R²** | 1 - (SS_res/SS_tot) | 0-1, higher is better | Proportion of variance explained |\n",
    "\n",
    "**Interpreting Our Results:**\n",
    "- **RMSE ≈ 30**: On average, our predictions are off by about $30K\n",
    "- **R² ≈ 0.75-0.85**: Our model explains ~75-85% of price variation\n",
    "- **Remaining variance**: Due to the random noise we added (which is unpredictable by design)\n",
    "\n",
    "**Train vs Test Comparison:**\n",
    "- If train metrics >> test metrics: **Overfitting** (model memorized training data)\n",
    "- If train ≈ test metrics: **Good generalization** ✓\n",
    "- If both are poor: **Underfitting** (model too simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46378b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the regression line\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot 1: Training data with regression line\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_train, y_train, alpha=0.6, label='Training Data')\n",
    "plt.plot(X_train, y_pred_train, color='red', linewidth=2, label='Regression Line')\n",
    "plt.xlabel('House Size (sq ft)')\n",
    "plt.ylabel('Price ($K)')\n",
    "plt.title('Training Data')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Test data with predictions\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_test, y_test, alpha=0.6, color='green', label='Test Data')\n",
    "plt.plot(X_test, y_pred_test, color='red', linewidth=2, label='Predictions')\n",
    "plt.xlabel('House Size (sq ft)')\n",
    "plt.ylabel('Price ($K)')\n",
    "plt.title(f'Test Data (R² = {test_metrics[\"r2\"]:.4f})')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b36ca83",
   "metadata": {},
   "source": [
    "## 3. Residual Analysis\n",
    "\n",
    "Residuals = Actual values - Predicted values\n",
    "\n",
    "Good models should have residuals that are:\n",
    "- Randomly distributed around zero\n",
    "- Normally distributed\n",
    "- No patterns (heteroscedasticity)\n",
    "\n",
    "### Why Analyze Residuals?\n",
    "\n",
    "Residuals reveal what our model **failed to capture**. If there are patterns in residuals, it means:\n",
    "1. A better model exists that could capture those patterns\n",
    "2. Our model assumptions might be violated\n",
    "3. We might need additional features or transformations\n",
    "\n",
    "### What We're Looking For:\n",
    "| Pattern | Problem | Solution |\n",
    "|---------|---------|----------|\n",
    "| Funnel shape | Heteroscedasticity | Log transform target |\n",
    "| Curved pattern | Non-linearity | Add polynomial terms |\n",
    "| Clusters | Missing categorical variable | Add more features |\n",
    "| Random scatter | Good model! ✓ | None needed |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4407c592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals\n",
    "residuals = y_test - y_pred_test\n",
    "\n",
    "# Residual plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Plot 1: Residuals vs Predicted\n",
    "axes[0].scatter(y_pred_test, residuals, alpha=0.6)\n",
    "axes[0].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[0].set_xlabel('Predicted Values')\n",
    "axes[0].set_ylabel('Residuals')\n",
    "axes[0].set_title('Residuals vs Predicted')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Histogram of residuals\n",
    "axes[1].hist(residuals, bins=20, edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1].set_xlabel('Residuals')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Distribution of Residuals')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Q-Q plot\n",
    "from scipy import stats\n",
    "stats.probplot(residuals, dist=\"norm\", plot=axes[2])\n",
    "axes[2].set_title('Q-Q Plot (Normality Check)')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Residual Statistics:\")\n",
    "print(f\"  Mean: {np.mean(residuals):.4f} (should be close to 0)\")\n",
    "print(f\"  Std Dev: {np.std(residuals):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636b9a79",
   "metadata": {},
   "source": [
    "## 4. Polynomial Regression\n",
    "\n",
    "When data has a non-linear relationship, we can use polynomial features.\n",
    "\n",
    "**Polynomial of degree 2:** y = ax² + bx + c\n",
    "\n",
    "### When to Use Polynomial Regression?\n",
    "\n",
    "Linear regression assumes a straight-line relationship. But many real-world relationships are curved:\n",
    "- Diminishing returns (more ads don't keep increasing sales linearly)\n",
    "- Growth curves (population, bacteria)\n",
    "- Physical phenomena (projectile motion, temperature effects)\n",
    "\n",
    "### How It Works:\n",
    "Instead of fitting: `y = β₀ + β₁x`\n",
    "We fit: `y = β₀ + β₁x + β₂x² + β₃x³ + ...`\n",
    "\n",
    "**Key Insight**: This is still \"linear\" regression! We're linear in the parameters (β), just using transformed features (x², x³).\n",
    "\n",
    "### The Danger of High Degrees:\n",
    "| Degree | Flexibility | Risk |\n",
    "|--------|-------------|------|\n",
    "| 1 | Low | Underfitting |\n",
    "| 2-3 | Moderate | Usually good |\n",
    "| 5+ | High | Overfitting |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccb40f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate non-linear data\n",
    "np.random.seed(42)\n",
    "X_nl = np.random.uniform(-3, 3, 150).reshape(-1, 1)\n",
    "y_nl = 0.5 * X_nl.flatten()**3 - 2 * X_nl.flatten()**2 + X_nl.flatten() + 3\n",
    "y_nl += np.random.normal(0, 2, 150)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(X_nl, y_nl, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('Non-Linear Data')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf0b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train_nl, X_test_nl, y_train_nl, y_test_nl = train_test_split(\n",
    "    X_nl, y_nl, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Compare different polynomial degrees\n",
    "degrees = [1, 2, 3, 5]\n",
    "results = []\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "X_line = np.linspace(X_nl.min(), X_nl.max(), 100).reshape(-1, 1)\n",
    "\n",
    "for idx, degree in enumerate(degrees):\n",
    "    # Create pipeline\n",
    "    poly_model = Pipeline([\n",
    "        ('poly_features', PolynomialFeatures(degree=degree, include_bias=False)),\n",
    "        ('linear_reg', LinearRegression())\n",
    "    ])\n",
    "    \n",
    "    # Train\n",
    "    poly_model.fit(X_train_nl, y_train_nl)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred_nl = poly_model.predict(X_test_nl)\n",
    "    y_line = poly_model.predict(X_line)\n",
    "    \n",
    "    # Evaluate\n",
    "    train_r2 = poly_model.score(X_train_nl, y_train_nl)\n",
    "    test_r2 = r2_score(y_test_nl, y_pred_nl)\n",
    "    \n",
    "    results.append({\n",
    "        'Degree': degree,\n",
    "        'Train R²': train_r2,\n",
    "        'Test R²': test_r2\n",
    "    })\n",
    "    \n",
    "    # Plot\n",
    "    ax = axes[idx]\n",
    "    ax.scatter(X_train_nl, y_train_nl, alpha=0.5, label='Train', color='blue')\n",
    "    ax.scatter(X_test_nl, y_test_nl, alpha=0.5, label='Test', color='green')\n",
    "    ax.plot(X_line, y_line, color='red', linewidth=2, label='Fit')\n",
    "    ax.set_title(f'Degree {degree}: Train R²={train_r2:.3f}, Test R²={test_r2:.3f}')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display results table\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nPolynomial Regression Results:\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce30058",
   "metadata": {},
   "source": [
    "## 5. Regularization: Ridge and Lasso\n",
    "\n",
    "Regularization helps prevent overfitting by adding a penalty term:\n",
    "\n",
    "- **Ridge (L2):** Adds penalty = α × Σ(coefficients²)\n",
    "- **Lasso (L1):** Adds penalty = α × Σ|coefficients|\n",
    "\n",
    "Lasso can shrink some coefficients to exactly zero (feature selection).\n",
    "\n",
    "### Why Regularization?\n",
    "\n",
    "When you have many features, standard linear regression can:\n",
    "1. **Overfit** by assigning large coefficients to noise\n",
    "2. **Be unstable** - small data changes cause large coefficient changes\n",
    "3. **Fail with multicollinearity** - correlated features cause issues\n",
    "\n",
    "### Ridge vs Lasso Comparison:\n",
    "\n",
    "| Aspect | Ridge (L2) | Lasso (L1) |\n",
    "|--------|------------|------------|\n",
    "| Penalty | Sum of squared coefficients | Sum of absolute coefficients |\n",
    "| Effect | Shrinks all coefficients | Shrinks some to exactly 0 |\n",
    "| Feature Selection | No (keeps all features) | Yes (eliminates features) |\n",
    "| Best When | All features somewhat useful | Many irrelevant features |\n",
    "\n",
    "### The α (alpha) Parameter:\n",
    "- **α = 0**: No regularization (standard linear regression)\n",
    "- **Small α**: Light penalty, coefficients close to OLS\n",
    "- **Large α**: Heavy penalty, coefficients shrink toward 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4f89d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data with many features (some irrelevant)\n",
    "np.random.seed(42)\n",
    "n_samples = 200\n",
    "n_features = 15\n",
    "\n",
    "X_reg = np.random.randn(n_samples, n_features)\n",
    "\n",
    "# Only 5 features are actually useful\n",
    "true_coef = np.array([3, -2, 1.5, 0, 0, -1, 0, 0, 0.5, 0, 0, 0, -0.5, 0, 0])\n",
    "y_reg = X_reg @ true_coef + np.random.normal(0, 0.5, n_samples)\n",
    "\n",
    "# Split and scale\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_reg)\n",
    "X_test_scaled = scaler.transform(X_test_reg)\n",
    "\n",
    "print(f\"Number of features: {n_features}\")\n",
    "print(f\"True non-zero coefficients: {np.sum(true_coef != 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7c2302",
   "metadata": {},
   "source": [
    "### ✅ Interpretation: Data Setup for Regularization\n",
    "\n",
    "**Our Experimental Design:**\n",
    "- **15 features** but only **5 are truly useful** (non-zero true coefficients)\n",
    "- True coefficients: `[3, -2, 1.5, 0, 0, -1, 0, 0, 0.5, 0, 0, 0, -0.5, 0, 0]`\n",
    "- 10 features are pure noise (coefficient = 0)\n",
    "\n",
    "**Why This Setup?**\n",
    "This mimics real-world scenarios where:\n",
    "- You have many potential predictors\n",
    "- Only some actually matter\n",
    "- You don't know which ones in advance\n",
    "\n",
    "**StandardScaler Purpose:**\n",
    "Regularization penalizes coefficient magnitude. If features have different scales (e.g., age: 0-100 vs income: 0-1,000,000), coefficients would be unfairly penalized. Scaling puts all features on equal footing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becb01c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge (α=1.0)': Ridge(alpha=1.0),\n",
    "    'Lasso (α=0.1)': Lasso(alpha=0.1)\n",
    "}\n",
    "\n",
    "comparison_results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train_reg)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    test_r2 = r2_score(y_test_reg, y_pred)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred))\n",
    "    n_nonzero = np.sum(np.abs(model.coef_) > 0.01)\n",
    "    \n",
    "    comparison_results.append({\n",
    "        'Model': name,\n",
    "        'Test R²': test_r2,\n",
    "        'Test RMSE': test_rmse,\n",
    "        'Non-zero Coef': n_nonzero\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Coefficients: {np.round(model.coef_, 3)}\")\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Model Comparison:\")\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39b5727",
   "metadata": {},
   "source": [
    "### ✅ Interpretation: Model Comparison Results\n",
    "\n",
    "**Coefficient Analysis:**\n",
    "\n",
    "1. **Linear Regression**:\n",
    "   - Assigns non-zero coefficients to ALL features\n",
    "   - Even the 10 irrelevant features get small but non-zero weights\n",
    "   - No built-in protection against overfitting\n",
    "\n",
    "2. **Ridge (L2)**:\n",
    "   - Shrinks all coefficients toward zero\n",
    "   - Irrelevant feature coefficients become very small but NOT zero\n",
    "   - Keeps all features in the model\n",
    "\n",
    "3. **Lasso (L1)**:\n",
    "   - Shrinks irrelevant feature coefficients to EXACTLY zero\n",
    "   - Effectively performs feature selection\n",
    "   - \"Non-zero Coef\" count should be close to 5 (our true number)\n",
    "\n",
    "**Performance Metrics:**\n",
    "All three should perform similarly on test data because:\n",
    "- Our true signal is clear\n",
    "- We have enough data\n",
    "- Regularization mainly helps with more complex/noisy scenarios\n",
    "\n",
    "The real difference is **interpretability**: Lasso tells you which features matter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba6e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize coefficient comparison\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "x_pos = np.arange(n_features)\n",
    "width = 0.2\n",
    "\n",
    "bars1 = ax.bar(x_pos - 1.5*width, models['Linear Regression'].coef_, width, \n",
    "               label='Linear', alpha=0.8)\n",
    "bars2 = ax.bar(x_pos - 0.5*width, models['Ridge (α=1.0)'].coef_, width, \n",
    "               label='Ridge', alpha=0.8)\n",
    "bars3 = ax.bar(x_pos + 0.5*width, models['Lasso (α=0.1)'].coef_, width, \n",
    "               label='Lasso', alpha=0.8)\n",
    "bars4 = ax.bar(x_pos + 1.5*width, true_coef, width, \n",
    "               label='True', alpha=0.8, color='black')\n",
    "\n",
    "ax.set_xlabel('Feature Index', fontsize=12)\n",
    "ax.set_ylabel('Coefficient Value', fontsize=12)\n",
    "ax.set_title('Coefficient Comparison: Linear vs Ridge vs Lasso', fontsize=14)\n",
    "ax.set_xticks(x_pos)\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.axhline(y=0, color='gray', linestyle='-', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nNote: Lasso shrinks irrelevant feature coefficients to zero!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e59eddd",
   "metadata": {},
   "source": [
    "## 6. Cross-Validation\n",
    "\n",
    "Cross-validation provides a more robust estimate of model performance.\n",
    "\n",
    "### Why Not Just Use Train-Test Split?\n",
    "\n",
    "A single train-test split has limitations:\n",
    "1. **Luck of the draw**: Results depend on which points end up in test set\n",
    "2. **Wastes data**: Test set isn't used for training\n",
    "3. **High variance**: Different splits give different results\n",
    "\n",
    "### K-Fold Cross-Validation:\n",
    "\n",
    "```\n",
    "Fold 1: [TEST] [Train] [Train] [Train] [Train]\n",
    "Fold 2: [Train] [TEST] [Train] [Train] [Train]\n",
    "Fold 3: [Train] [Train] [TEST] [Train] [Train]\n",
    "Fold 4: [Train] [Train] [Train] [TEST] [Train]\n",
    "Fold 5: [Train] [Train] [Train] [Train] [TEST]\n",
    "```\n",
    "\n",
    "**Process:**\n",
    "1. Divide data into K equal parts (folds)\n",
    "2. Train on K-1 folds, test on remaining fold\n",
    "3. Repeat K times, each fold serves as test once\n",
    "4. Average the K scores for final estimate\n",
    "\n",
    "**Benefits:**\n",
    "- Every data point is tested exactly once\n",
    "- More reliable performance estimate\n",
    "- Standard deviation shows result stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4689f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train_scaled, y_train_reg, \n",
    "                             cv=5, scoring='r2')\n",
    "    cv_results.append({\n",
    "        'Model': name,\n",
    "        'Mean R²': scores.mean(),\n",
    "        'Std R²': scores.std(),\n",
    "        'Min R²': scores.min(),\n",
    "        'Max R²': scores.max()\n",
    "    })\n",
    "    \n",
    "cv_df = pd.DataFrame(cv_results)\n",
    "print(\"5-Fold Cross-Validation Results:\")\n",
    "print(cv_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc47c200",
   "metadata": {},
   "source": [
    "### ✅ Interpretation: Cross-Validation Results\n",
    "\n",
    "**Understanding the Output:**\n",
    "\n",
    "| Metric | Meaning |\n",
    "|--------|---------|\n",
    "| Mean R² | Average performance across all 5 folds |\n",
    "| Std R² | Consistency of performance (lower = more stable) |\n",
    "| Min/Max R² | Range of performance across folds |\n",
    "\n",
    "**What Good Results Look Like:**\n",
    "- **High Mean R²**: Model performs well on average\n",
    "- **Low Std R²**: Performance is consistent across different data subsets\n",
    "- **Small Min-Max gap**: No problematic folds\n",
    "\n",
    "**Comparing Models:**\n",
    "- Similar Mean R² suggests comparable predictive power\n",
    "- Lower Std suggests more reliable predictions\n",
    "- If regularized models (Ridge/Lasso) have similar or better scores with lower variance, prefer them!\n",
    "\n",
    "**Practical Interpretation:**\n",
    "\"This model achieves R² of X ± Y on unseen data\" is more trustworthy than a single test set score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed1f8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CV results\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "model_names = [r['Model'] for r in cv_results]\n",
    "means = [r['Mean R²'] for r in cv_results]\n",
    "stds = [r['Std R²'] for r in cv_results]\n",
    "\n",
    "bars = ax.bar(model_names, means, yerr=stds, capsize=5, alpha=0.8, \n",
    "              color=['steelblue', 'darkorange', 'green'])\n",
    "\n",
    "ax.set_ylabel('R² Score', fontsize=12)\n",
    "ax.set_title('Cross-Validation Results (5-Fold)', fontsize=14)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for bar, mean, std in zip(bars, means, stds):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + std + 0.01,\n",
    "            f'{mean:.3f}±{std:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730aea37",
   "metadata": {},
   "source": [
    "## 7. Hyperparameter Tuning\n",
    "\n",
    "Find the best regularization parameter (α) using Grid Search.\n",
    "\n",
    "### What is Hyperparameter Tuning?\n",
    "\n",
    "**Parameters vs Hyperparameters:**\n",
    "| Type | Set By | Examples |\n",
    "|------|--------|----------|\n",
    "| Parameters | Algorithm (learning) | Coefficients, weights |\n",
    "| Hyperparameters | You (before training) | α, degree, learning rate |\n",
    "\n",
    "### Grid Search Process:\n",
    "\n",
    "1. **Define parameter grid**: List of values to try (e.g., α = [0.001, 0.01, 0.1, 1, 10, 100])\n",
    "2. **For each value**: Train model using cross-validation\n",
    "3. **Record scores**: Track performance for each setting\n",
    "4. **Select best**: Choose hyperparameter with highest CV score\n",
    "\n",
    "### Why Grid Search?\n",
    "- Systematic exploration of hyperparameter space\n",
    "- Combined with CV for reliable estimates\n",
    "- Avoids manual trial-and-error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44e5f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Grid search for Ridge\n",
    "ridge_grid = GridSearchCV(\n",
    "    Ridge(), \n",
    "    param_grid, \n",
    "    cv=5, \n",
    "    scoring='r2',\n",
    "    return_train_score=True\n",
    ")\n",
    "ridge_grid.fit(X_train_scaled, y_train_reg)\n",
    "\n",
    "# Grid search for Lasso\n",
    "lasso_grid = GridSearchCV(\n",
    "    Lasso(max_iter=10000), \n",
    "    param_grid, \n",
    "    cv=5, \n",
    "    scoring='r2',\n",
    "    return_train_score=True\n",
    ")\n",
    "lasso_grid.fit(X_train_scaled, y_train_reg)\n",
    "\n",
    "print(\"Best Parameters:\")\n",
    "print(f\"  Ridge: α = {ridge_grid.best_params_['alpha']}, R² = {ridge_grid.best_score_:.4f}\")\n",
    "print(f\"  Lasso: α = {lasso_grid.best_params_['alpha']}, R² = {lasso_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89365ea1",
   "metadata": {},
   "source": [
    "### ✅ Interpretation: Grid Search Results\n",
    "\n",
    "**Best Parameters Found:**\n",
    "The optimal α values balance model complexity and generalization.\n",
    "\n",
    "**Understanding α Selection:**\n",
    "- **α too small**: Effectively no regularization, overfitting risk\n",
    "- **α too large**: Over-penalizes, underfitting risk\n",
    "- **Optimal α**: Best bias-variance tradeoff\n",
    "\n",
    "**For Ridge:**\n",
    "- Usually optimal α is moderate (0.1 to 10)\n",
    "- Depends on feature scales and noise level\n",
    "\n",
    "**For Lasso:**\n",
    "- Often needs smaller α than Ridge\n",
    "- Too large α zeros out ALL coefficients\n",
    "- Optimal value keeps important features while eliminating noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10229910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot alpha vs R² score\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "alphas = param_grid['alpha']\n",
    "\n",
    "# Ridge results\n",
    "ridge_means = ridge_grid.cv_results_['mean_test_score']\n",
    "ridge_stds = ridge_grid.cv_results_['std_test_score']\n",
    "\n",
    "axes[0].semilogx(alphas, ridge_means, 'o-', linewidth=2, markersize=8)\n",
    "axes[0].fill_between(alphas, ridge_means - ridge_stds, ridge_means + ridge_stds, alpha=0.2)\n",
    "axes[0].axvline(ridge_grid.best_params_['alpha'], color='red', linestyle='--', \n",
    "                label=f'Best α = {ridge_grid.best_params_[\"alpha\"]}')\n",
    "axes[0].set_xlabel('Alpha (log scale)', fontsize=12)\n",
    "axes[0].set_ylabel('R² Score', fontsize=12)\n",
    "axes[0].set_title('Ridge: Alpha vs R² Score', fontsize=14)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Lasso results\n",
    "lasso_means = lasso_grid.cv_results_['mean_test_score']\n",
    "lasso_stds = lasso_grid.cv_results_['std_test_score']\n",
    "\n",
    "axes[1].semilogx(alphas, lasso_means, 'o-', linewidth=2, markersize=8, color='green')\n",
    "axes[1].fill_between(alphas, lasso_means - lasso_stds, lasso_means + lasso_stds, \n",
    "                     alpha=0.2, color='green')\n",
    "axes[1].axvline(lasso_grid.best_params_['alpha'], color='red', linestyle='--', \n",
    "                label=f'Best α = {lasso_grid.best_params_[\"alpha\"]}')\n",
    "axes[1].set_xlabel('Alpha (log scale)', fontsize=12)\n",
    "axes[1].set_ylabel('R² Score', fontsize=12)\n",
    "axes[1].set_title('Lasso: Alpha vs R² Score', fontsize=14)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a01a3af",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Linear Regression** finds the best-fit line by minimizing squared errors\n",
    "2. **Polynomial Regression** captures non-linear relationships but risks overfitting\n",
    "3. **Ridge (L2)** shrinks coefficients to reduce overfitting\n",
    "4. **Lasso (L1)** can eliminate features by shrinking coefficients to zero\n",
    "5. **Cross-validation** provides robust model evaluation\n",
    "6. **Hyperparameter tuning** helps find optimal regularization strength\n",
    "\n",
    "### Metrics Interpretation:\n",
    "- **R² = 1**: Perfect prediction\n",
    "- **R² = 0**: Model predicts the mean\n",
    "- **R² < 0**: Model is worse than predicting the mean\n",
    "- **RMSE**: Average prediction error (in same units as target)\n",
    "\n",
    "### When to Use Each Model:\n",
    "\n",
    "| Scenario | Recommended Model |\n",
    "|----------|-------------------|\n",
    "| Clear linear relationship, few features | Linear Regression |\n",
    "| Many features, all potentially useful | Ridge |\n",
    "| Many features, some irrelevant | Lasso |\n",
    "| Clear non-linear pattern | Polynomial Regression |\n",
    "| Unsure about linearity | Try multiple, compare with CV |\n",
    "\n",
    "### Complete ML Pipeline Checklist:\n",
    "- [ ] Explore and visualize data\n",
    "- [ ] Split into train/test sets\n",
    "- [ ] Preprocess (scale, encode, handle missing)\n",
    "- [ ] Select appropriate model(s)\n",
    "- [ ] Train with cross-validation\n",
    "- [ ] Tune hyperparameters\n",
    "- [ ] Evaluate on held-out test set\n",
    "- [ ] Analyze residuals\n",
    "- [ ] Document findings and deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529a57d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model comparison on test set\n",
    "print(\"=\"*60)\n",
    "print(\"FINAL MODEL COMPARISON ON TEST SET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "final_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Best Ridge': Ridge(alpha=ridge_grid.best_params_['alpha']),\n",
    "    'Best Lasso': Lasso(alpha=lasso_grid.best_params_['alpha'])\n",
    "}\n",
    "\n",
    "for name, model in final_models.items():\n",
    "    model.fit(X_train_scaled, y_train_reg)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    r2 = r2_score(y_test_reg, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred))\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Test R²:   {r2:.4f}\")\n",
    "    print(f\"  Test RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1850aac4",
   "metadata": {},
   "source": [
    "### ✅ Final Interpretation: Model Selection\n",
    "\n",
    "**Final Results Analysis:**\n",
    "\n",
    "Compare the three models on the test set (data never seen during training or tuning):\n",
    "\n",
    "1. **Linear Regression**: Baseline performance, no regularization\n",
    "2. **Best Ridge**: Optimal L2 regularization\n",
    "3. **Best Lasso**: Optimal L1 regularization with feature selection\n",
    "\n",
    "**Decision Criteria:**\n",
    "\n",
    "| If... | Then Choose... |\n",
    "|-------|----------------|\n",
    "| All similar R² | Lasso (simpler model with fewer features) |\n",
    "| Ridge significantly better | Ridge (all features contribute) |\n",
    "| Interpretability matters | Lasso (clear feature importance) |\n",
    "| Deployment simplicity | Lasso (fewer features to collect/process) |\n",
    "\n",
    "**Final Thoughts:**\n",
    "\n",
    "In this experiment, we demonstrated the complete regression pipeline:\n",
    "1. ✅ Generated and explored data\n",
    "2. ✅ Built baseline linear model\n",
    "3. ✅ Analyzed residuals to validate assumptions\n",
    "4. ✅ Extended to polynomial for non-linear data\n",
    "5. ✅ Applied regularization for feature selection\n",
    "6. ✅ Used cross-validation for reliable estimates\n",
    "7. ✅ Tuned hyperparameters with grid search\n",
    "8. ✅ Compared models on held-out test set\n",
    "\n",
    "This systematic approach ensures robust, generalizable models that perform well on new data!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv-python-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
